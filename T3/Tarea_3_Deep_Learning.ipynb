{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnpr1VPKUwY9"
      },
      "source": [
        "# T3 CC6204 - Deep Learning\n",
        "\n",
        "\n",
        "### **Por: Álvaro Morales Torres**\n",
        "\n",
        "15-11-2023\n",
        "\n",
        "Trabajado en local con CUDA y PyTorch\n",
        "\n",
        "SPECS:\n",
        "\n",
        "**CPU**: AMD Ryzen 7 5700XX (8 Core) @4.5 GHz.\n",
        "\n",
        "**GPU**: NVIDIA GeForce RTX 3060 Ti (8GB VRAM).\n",
        "\n",
        "16 GB RAM @ 3200 MHz.\n",
        "\n",
        "En esta tarea van a crear una red neuronal que clasifique mensajes como spam o no spam. Lo primero es descargar la data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZkXXLb0VUmFX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2023-11-15 08:07:36--  https://www.ivan-sipiran.com/downloads/spam.csv\n",
            "Loaded CA certificate '/usr/ssl/certs/ca-bundle.crt'\n",
            "Resolving www.ivan-sipiran.com (www.ivan-sipiran.com)... 66.96.149.31\n",
            "Connecting to www.ivan-sipiran.com (www.ivan-sipiran.com)|66.96.149.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 471781 (461K)\n",
            "Saving to: 'spam.csv'\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 10%  252K 2s\n",
            "    50K .......... .......... .......... .......... .......... 21%  252K 1s\n",
            "   100K .......... .......... .......... .......... .......... 32% 29.1M 1s\n",
            "   150K .......... .......... .......... .......... .......... 43% 5.73M 1s\n",
            "   200K .......... .......... .......... .......... .......... 54%  264K 1s\n",
            "   250K .......... .......... .......... .......... .......... 65% 38.7M 0s\n",
            "   300K .......... .......... .......... .......... .......... 75% 7.13M 0s\n",
            "   350K .......... .......... .......... .......... .......... 86% 26.8M 0s\n",
            "   400K .......... .......... .......... .......... .......... 97%  266K 0s\n",
            "   450K ..........                                            100%  205G=0.8s\n",
            "\n",
            "2023-11-15 08:07:38 (580 KB/s) - 'spam.csv' saved [471781/471781]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.ivan-sipiran.com/downloads/spam.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9567d6oVknI"
      },
      "source": [
        "Los datos vienen en un archivo CSV que contiene dos columnas \"text\" y \"label\". La columna \"text\" contiene el texto del mensaje y la columna \"label\" contiene las etiquetas \"ham\" y \"spam\". Un mensaje \"ham\" es un mensaje que no se considera spam.\n",
        "\n",
        "# Tarea\n",
        "El objetivo de la tarea es crear una red neuronal que clasifique los datos entregados. Para lograr esto debes:\n",
        "\n",
        "\n",
        "\n",
        "*   Implementar el pre-procesamiento de los datos que creas necesario.\n",
        "*   Particionar los datos en 70% entrenamiento, 10% validación y 20% test.\n",
        "*   Usa los datos de entrenamiento y valiadación para tus experimentos y sólo usa el conjunto de test para reportar el resultado final.\n",
        "\n",
        "Para el diseño de la red neuronal puedes usar una red neuronal recurrente o una red basada en transformers. El objetivo de la tarea no es obtener el performance ultra máximo, sino entender qué decisiones de diseño afectan la solución de un problema como este. Lo que si es necesario (como siempre) es que discutas los resultados y decisiones realizadas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {
        "id": "5pmzo1gcVXvY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ]
          },
          "execution_count": 606,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's take a look at the data\n",
        "import pandas as pd\n",
        "df = pd.read_csv('spam.csv', encoding='utf-8', dtype=str, keep_default_na=False)\n",
        "# keep_default_na=False to avoid pandas converting empty strings and numbers to NaN\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 607,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows:  5572\n",
            "Spam:  746\n",
            "Ham:  4617\n",
            "Average text len:  78.42623833452978\n",
            "Median text len:  59.0\n",
            "Longest text len:  910\n"
          ]
        }
      ],
      "source": [
        "# simple enough.\n",
        "# how much data do we have?\n",
        "print(\"Total rows: \", len(df))\n",
        "# how many spam and ham?\n",
        "print(\"Spam: \", len(df[df['label'] == \"spam\"]))\n",
        "print(\"Ham: \", len(df[df['label'] == \"ham\"]))\n",
        "\n",
        "# how long are the texts?\n",
        "# average text length\n",
        "print(\"Average text len: \", df['text'].map(lambda x: len(x)).mean())\n",
        "# median text length\n",
        "print(\"Median text len: \", df['text'].map(lambda x: len(x)).median())\n",
        "# longest text length\n",
        "print(\"Longest text len: \", df['text'].map(lambda x: len(x)).max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parece que la mayoría de textos son cortos, mientras que la minoría son más largos. Tendré esto en mente al elegir el tamaño de la secuencia de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Diseñemos una RNN para resolver este problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Pre-procesamiento de los datos\n",
        "\n",
        "La idea es hacer esto a nivel de palabras. Por lo tanto necesitamos deshacernos de la puntuación y de las mayúsculas. Y por supuesto, dividir cada mensaje en palabras individuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  go until jurong point crazy available only in ...   ham\n",
              "1                            ok lar joking wif u oni   ham\n",
              "2  free entry in 2 a wkly comp to win fa cup fina...  spam\n",
              "3        u dun say so early hor u c already then say   ham\n",
              "4  nah i dont think he goes to usf he lives aroun...   ham"
            ]
          },
          "execution_count": 608,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from string import punctuation\n",
        "\n",
        "# remove punctuation and set everything to lowercase\n",
        "df['text'] = df['text'].map(lambda x: ''.join(c for c in x if c not in punctuation).lower())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words:  83643\n",
            "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat', 'ok', 'lar', 'joking', 'wif', 'u', 'oni', 'free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'questionstd', 'txt', 'ratetcs', 'apply', '08452810075over18s', 'u', 'dun', 'say', 'so', 'early', 'hor', 'u', 'c', 'already', 'then', 'say', 'nah', 'i', 'dont', 'think', 'he', 'goes', 'to', 'usf', 'he', 'lives', 'around', 'here', 'though', 'freemsg', 'hey', 'there', 'darling', 'its', 'been', '3', 'weeks', 'now', 'and', 'no', 'word', 'back', 'id', 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still']\n"
          ]
        }
      ],
      "source": [
        "# now we get all the words\n",
        "all_text = ' '.join(df['text'])\n",
        "words = all_text.split()\n",
        "print(\"Total words: \", len(words))\n",
        "print(words[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay palabras medias raras y sin sentido, pero podrían ser representativas del spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2: Codificar palabras y embedding de labels\n",
        "\n",
        "Cada palabra es mapeada a un int."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    go until jurong point crazy available only in ...\n",
            "1                              ok lar joking wif u oni\n",
            "2    free entry in 2 a wkly comp to win fa cup fina...\n",
            "Name: text, dtype: object\n",
            "[[45, 447, 4303, 786, 704, 670, 64, 8, 1230, 89, 119, 350, 1231, 152, 2851, 1232, 66, 56, 4304, 137], [48, 307, 1384, 431, 6, 1809], [47, 448, 8, 22, 4, 745, 891, 1, 179, 1810, 1126, 616, 1811, 2196, 261, 2197, 69, 1810, 1, 1812, 1, 308, 448, 2852, 78, 2853, 375, 2854]]\n",
            "Unique words:  9396\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# build word dictionary {word: frequency}\n",
        "counts = Counter(words)\n",
        "# sort words by frequency\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "# dictionary to map words to integers\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "# turn each text into an array of integers\n",
        "text_ints = []\n",
        "for text in df['text']:\n",
        "    text_ints.append([vocab_to_int[word] for word in text.split()])\n",
        "print(df['text'][0:3])\n",
        "print(text_ints[:3])\n",
        "print(\"Unique words: \", len((vocab_to_int)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y para las etiquetas, digamos que 0 es ham y 1 es spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     ham\n",
            "1     ham\n",
            "2    spam\n",
            "Name: label, dtype: object\n",
            "[0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "bin_labels = []\n",
        "for label in df['label']:\n",
        "    if label == \"spam\":\n",
        "        bin_labels.append(1)\n",
        "    else:\n",
        "        bin_labels.append(0)\n",
        "print(df['label'][0:3])\n",
        "print(bin_labels[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que tenemos los textos codificados, veamos si hay reviews de len 0 y cuál es el len promedio, mediano y máximo de secuecnias.\n",
        "\n",
        "Estos datos nos ayudarán a tomar una decisión informada al elegir el tamaño de la secuencia de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total texts: 5572\n",
            "0-len texts: 3\n",
            "Average text len: 67.95121951219512\n",
            "Median text len: 41\n",
            "Maximum text len: 171\n"
          ]
        }
      ],
      "source": [
        "lens = Counter([len(x) for x in text_ints])\n",
        "print(f\"Total texts: {len(text_ints)}\")\n",
        "print(f\"0-len texts: {lens[0]}\")\n",
        "print(f\"Average text len: {sum(lens.values()) / len(lens)}\")\n",
        "print(f\"Median text len: {sorted(lens)[len(lens) // 2]}\")\n",
        "print(f\"Maximum text len: {max(lens)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que en promedio las reviews tienen 69 palabras, la mediana es de 41, y el máximo es 171. parece haber una varianza bastante alta en el largo de las secuencias.\n",
        "\n",
        "Idealmente, no queremos que la vasta mayoría de los features sean 0's. Por lo tanto, elegiremos un tamaño de secuencia de entrada de 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total texts: 5569\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# remove texts with 0 length\n",
        "non_zero_idx = [ii for ii, text in enumerate(text_ints) if len(text) != 0]\n",
        "text_ints = [text_ints[ii] for ii in non_zero_idx]\n",
        "bin_labels = np.array([bin_labels[ii] for ii in non_zero_idx])\n",
        "print(f\"Total texts: {len(text_ints)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: Padding\n",
        "\n",
        "Definiendo `SEQ_LEN = 50`, hagamos padding de los textos para que todos tengan el mismo largo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEQ_LEN = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 615,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_features(text_ints, seq_len = SEQ_LEN):\n",
        "  features = np.zeros((len(text_ints), seq_len), dtype=int)\n",
        "\n",
        "  #Para cada review, se coloca en la matriz\n",
        "  for i, row in enumerate(text_ints):\n",
        "    features[i, -len(row):] = np.array(row)[:seq_len]\n",
        "  \n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5569, 50)\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   47  448    8   22    4]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0  840  116   66 1570   42  100  193  585   21]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0   72  222   13]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  672   72    4]\n",
            " [   0    0    0    0    0    0    0    0  129   13   92 1024  788   27]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1816 2861    1]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  194    3   17]\n",
            " [ 170  100 1572   12    5  144  521    1  420    3   12   40 4309    2]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   37 4323  953    1  309]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  108    3 1029    5  451]]\n"
          ]
        }
      ],
      "source": [
        "features = pad_features(text_ints)\n",
        "print(features.shape)\n",
        "print(features[:28,13:27])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Puede que esto parezca demasiado padding, pero los resultados terminaron siendo bastante buenos (spoiler)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Conujntos de entrenamiento, validación y test\n",
        "\n",
        "Habíamos dicho 70% train, 10% val y 20% test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t\t\tFeatures:\t%'s:\n",
            "Train set: \t\t(3898, 50) \t69.99 \n",
            "Validation set: \t(557, 50) \t10.00 \n",
            "Test set: \t\t(1114, 50) \t20.00\n"
          ]
        }
      ],
      "source": [
        "TRAIN_RATIO = 0.7\n",
        "TEST_VS_VAL_RATIO = 0.3334\n",
        "\n",
        "# split the data. training set = 70%, validation set = 10%, test set = 20%\n",
        "split_idx = int(len(features)*TRAIN_RATIO)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = bin_labels[:split_idx], bin_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*TEST_VS_VAL_RATIO)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "assert train_x.shape[0] + val_x.shape[0] + test_x.shape[0] == features.shape[0], \"Something went wrong with the split\"\n",
        "\n",
        "print(\"\\t\\t\\tFeatures:\\t%'s:\")\n",
        "print(\"Train set: \\t\\t{} \\t{:.2f}\".format(train_x.shape, 100*train_x.shape[0]/features.shape[0]),\n",
        "      \"\\nValidation set: \\t{} \\t{:.2f}\".format(val_x.shape, 100*val_x.shape[0]/features.shape[0]),\n",
        "      \"\\nTest set: \\t\\t{} \\t{:.2f}\".format(test_x.shape, 100*test_x.shape[0]/features.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Idealmente queremos que la cantidad de elementos en train sean divisibles por el batch_size (en caso de que no lo sea, podemos pasarle el parámetro `drop_last=True` al DataLoader, pero esto no es ideal porque se ignorarían los datos restantes).\n",
        "\n",
        "Desafortunadamente, 3898 solo es divisible 1, 2, 1949 y 3898. Por lo que habrá que ocupar `drop_last=True` y escoger un batch_size tal que no ignoremos muchos datos.\n",
        "\n",
        "3898 es muy cercano a 3900, que es divisible por 50. Por lo tanto el batch_size será 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Creación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usaremos una RNN igual a la que se usó en el Lab 11. Es decir con:\n",
        "- Una capa de embedding que convierte los tokens (palabras) a vectores de cierto tamaño (parámetro)\n",
        "- Una capa LTSM definida por el tamaño del estado oculto y el número de capas (parámetros)\n",
        "- Una capa de salida FC que mapea la salida del LSTM a una salida de cierto tamaño (parámetro)\n",
        "- Una capa de activación sigmoide con salida 0 o 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 628,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rng dependent stuff starts here:\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "SEED = 6669 # lml and nice\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos nuestros data loaders. Como se dijo antes, el batch_size será 50, y necesitamos drop_last=True porque nuestro conjunto de train no es exactamente divisible por 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 629,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create Datasets and DataLoaders\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 630,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definición del modelo, como fue descrito anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 631,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden) \n",
        "        # take the last output of the LSTM\n",
        "        lstm_out = lstm_out[:,-1,:]    \n",
        "        # dropout and fully-connected\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid\n",
        "        sig_out = self.sig(out)\n",
        "        # return sigmoid and the last hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size=BATCH_SIZE):\n",
        "        # create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        if(train_on_gpu):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instanciamiento (seteo de los parámetros mencionados):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 632,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(9397, 50)\n",
            "  (lstm): LSTM(50, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instanciate the RNN\n",
        "vocab_size = len(vocab_to_int) + 1 # +1 for zero padding + our word tokens\n",
        "output_size = 1 # binary classification\n",
        "embedding_dim = 50 # word embedding dimension\n",
        "hidden_dim = 256 # hidden dimension\n",
        "n_layers = 2 # number of LSTM layers\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A entrenar el modelo. Un learning rate de 0.001 fue suficientemente bueno.\n",
        "\n",
        "Por otro lado, Cross Entropy Loss es ideal para clasificación binaria, y Adam es un excelente optimizador para este problema.\n",
        "\n",
        "También usaremos gradient clipping para evitar gradientes muy grandes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 633,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Después de algunos intentos con varios números de epochs, el loss de validación dejó de decrecer a los 4 o 5 epochs, y para valores más grandes de epoch empezó a aumentar hasta overfittear.\n",
        "\n",
        "5 epochs parece ser un buen valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 634,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/5... Step: 50... Loss: 0.118664... Val Loss: 0.218780\n",
            "Epoch: 2/5... Step: 100... Loss: 0.158365... Val Loss: 0.180397\n",
            "Epoch: 2/5... Step: 150... Loss: 0.080311... Val Loss: 0.146888\n",
            "Epoch: 3/5... Step: 200... Loss: 0.082398... Val Loss: 0.116931\n",
            "Epoch: 4/5... Step: 250... Loss: 0.092349... Val Loss: 0.110323\n",
            "Epoch: 4/5... Step: 300... Loss: 0.006044... Val Loss: 0.123274\n",
            "Epoch: 5/5... Step: 350... Loss: 0.014892... Val Loss: 0.091375\n"
          ]
        }
      ],
      "source": [
        "# arrays for plotting\n",
        "train_losses_for_plot = []\n",
        "val_losses_for_plot = []\n",
        "steps_for_plot = []\n",
        "# training params\n",
        "EPOCHS = 5\n",
        "counter = 0\n",
        "print_every = 50\n",
        "clip = 5 # gradient clipping\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(EPOCHS):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(BATCH_SIZE)\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        # Create new vars for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "        net.zero_grad()\n",
        "        # forward pass\n",
        "        output, h = net(inputs, h)\n",
        "        # calculate loss\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # gradient clipping\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        # messages\n",
        "        if counter % print_every == 0:\n",
        "            # validation loss\n",
        "            val_h = net.init_hidden(BATCH_SIZE)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "            net.train()\n",
        "            # append losses to plotting arrays\n",
        "            train_losses_for_plot.append(loss.item())\n",
        "            val_losses_for_plot.append(np.mean(val_losses))\n",
        "            steps_for_plot.append(counter)\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, EPOCHS),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses))\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the training losses\n",
        "x = steps_for_plot\n",
        "plt.plot(x, train_losses_for_plot , label='Training loss')\n",
        "plt.plot(x, val_losses_for_plot , label='Validation loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`0.091375`\n",
        "\n",
        "Este es el loss de validación más bajo que logré obtener."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 7: Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos cómo le fue:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.091402\n",
            "Test accuracy: 0.963196\n"
          ]
        }
      ],
      "source": [
        "# get test accuracy\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "# iniciate hidden state\n",
        "h = net.init_hidden(BATCH_SIZE)\n",
        "# set network to eval mode\n",
        "net.eval()\n",
        "for inputs, labels in test_loader:\n",
        "    h = tuple([each.data for each in h])\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    output, h = net(inputs, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    # convert probabilities to classes (0,1)\n",
        "    pred = torch.round(output.squeeze())  \n",
        "    # compare label predictions\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.6f}\".format(np.mean(test_losses)))\n",
        "# Accuracy de test\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.6f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 637,
      "metadata": {},
      "outputs": [],
      "source": [
        "# waos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`0.091402` en loss de test y un accuracy de **96%**. Nada mal. Parece que el modelo ha sido un éxito."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Inferencia\n",
        "\n",
        "Solo para cerrar, como los inputs son textos cortos y el ser humano entiende intuitivamente cuándo algo es spam y cuándo no, pongamos el modelo a prueba con datos inventados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 640,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() \n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "    return test_ints\n",
        "\n",
        "def predict(net, test_review, sequence_length=SEQ_LEN):\n",
        "    net.eval()\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    seq_length = sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    batch_size = feature_tensor.size(0)\n",
        "    h = net.init_hidden(batch_size)\n",
        "    if(train_on_gpu):\n",
        "      feature_tensor = feature_tensor.cuda()\n",
        "    output, h = net(feature_tensor, h)\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('predicted value before rounding: {:.6f}'.format(output.item()))\n",
        "    # print custom response based on whether test_review is pos/neg\n",
        "    if(pred.item()==1):\n",
        "      print('SPAM!')\n",
        "    else:\n",
        "      print('NOT SPAM!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 673,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted value before rounding: 0.032098\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.129617\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.822795\n",
            "SPAM!\n",
            "predicted value before rounding: 0.992146\n",
            "SPAM!\n",
            "predicted value before rounding: 0.005856\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.737476\n",
            "SPAM!\n",
            "predicted value before rounding: 0.782233\n",
            "SPAM!\n",
            "predicted value before rounding: 0.063951\n",
            "NOT SPAM!\n"
          ]
        }
      ],
      "source": [
        "test_spam_1 = \"lonely single moms in your area want to meet you click here\"\n",
        "test_spam_2 = \"free money for you just sign up here for free money\"\n",
        "test_spam_3 = \"congratulations you won a free trip to the bahamas click here to claim your prize\"\n",
        "test_spam_4 = \"you have been selected to receive a free gift card click here to claim your free money\"\n",
        "test_spam_5 = \"your computer may be in danger click here to download a fix\"\n",
        "test_spam_6 = \"a prince wants to give you money for no reason type your bank account info here for free money\"\n",
        "test_spam_7 = \"free cash click here to claim your free cash now\"\n",
        "test_spam_8 = \"h hi c can i p please have your credit card n number t the date and the t three numbers on the back? t thanks...\"\n",
        "\n",
        "predict(net, test_spam_1)\n",
        "predict(net, test_spam_2)\n",
        "predict(net, test_spam_3)\n",
        "predict(net, test_spam_4)\n",
        "predict(net, test_spam_5)\n",
        "predict(net, test_spam_6)\n",
        "predict(net, test_spam_7)\n",
        "predict(net, test_spam_8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 674,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted value before rounding: 0.007543\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.067992\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.005268\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.003132\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.001183\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.002254\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.002151\n",
            "NOT SPAM!\n",
            "predicted value before rounding: 0.002056\n",
            "NOT SPAM!\n"
          ]
        }
      ],
      "source": [
        "test_not_spam_1 = \"hey dude what's up are you coming to the party tonight? call me when you see this, thanks\"\n",
        "test_not_spam_2 = \"please PLEASSSSSSSEEEEEE for the love of god tell you you finished the deep learn ing home work\"\n",
        "test_not_spam_3 = \"you should love yourself NOW!\"\n",
        "test_not_spam_4 = \"hey man, we're going to the movies tonight, wanna come?\"\n",
        "test_not_spam_5 = \"did you seriously spend your entire pay check on a n i me figures again? seriously?\"\n",
        "test_not_spam_6 = \"stop ignoring me, what are we supposed to do now? you're such a jerk you god damn we e b, how are we gonna make it this month?\"\n",
        "test_not_spam_7 = \"you know what? no we're done. we're over unless you stop watching that mo e trash, you don't even look at me anymore\"\n",
        "test_not_spam_8 = \"hey man, wanna play league?\"\n",
        "\n",
        "predict(net, test_not_spam_1)\n",
        "predict(net, test_not_spam_2)\n",
        "predict(net, test_not_spam_3)\n",
        "predict(net, test_not_spam_4)\n",
        "predict(net, test_not_spam_5)\n",
        "predict(net, test_not_spam_6)\n",
        "predict(net, test_not_spam_7)\n",
        "predict(net, test_not_spam_8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hmm... parece que el modelo no es tan bueno como pensábamos. O sí?\n",
        "\n",
        "Hay que recordar que un modelo solo puede llegar a ser tan bueno como la data entregada se lo permite.\n",
        "\n",
        "Recordemos que, de los 5572 textos que teníamos, solo 746 eran spam. Solo el 13% de la data. Así que primero que nada, es esperable que sea mejor detectando cuando algo ***no*** es spam que cuando algo es spam.\n",
        "\n",
        "Pero además, tenemos un muestreo bastante chico de \"*lo que puede ser llamado spam*\". El modelo solo tiene conocimiento de un slice muy chico de lo que se puede considerar como spam, y al parecer terminó siendo un slice demasiado cesgado. No necesariamente es data que representa bien el problema.\n",
        "\n",
        "A pesar de que se obtuvieron resultados impresionantes, i.e: un accuracy de test del 96%, estos resultados no significan mucho en el gran esquema de las cosas, ya que estas métricas solo son relativas a los datos usados, y no son necesariamente la mejor representación del mundo real, o de lo que podría esperar el usuario.\n",
        "\n",
        "Hay que tener estas cosas en mente al diseñar modelos de Deep Learning. El verdadero *test* de un modelo es su desempeño en el mundo real."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
